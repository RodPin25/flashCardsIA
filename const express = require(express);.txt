const express = require("express");
const fetch = require("node-fetch"); 
const app=express();
const PORT=3000;

const {
    GoogleGenerativeAI,
    HarmCategory,
    HarmBlockThreshold,
  } = require("@google/generative-ai");
  const { GoogleAIFileManager } = require("@google/generative-ai/server");
  
  const apiKey = 809444909519; //La API Key es personal y deberia de cambiar conforme cada usuario
  const genAI = new GoogleGenerativeAI(apiKey); //Se crea un objeto de la clase GoogleGenerativeAI
  const fileManager = new GoogleAIFileManager(apiKey); //Se crea un objeto de la clase GoogleAIFileManager

  
  
  /**
   * Uploads the given file to Gemini.
   *
   * See https://ai.google.dev/gemini-api/docs/prompting_with_media
   */
  async function uploadToGemini(path, mimeType) {
    const uploadResult = await fileManager.uploadFile(path, {
      mimeType,
      displayName: path,
    });
    const file = uploadResult.file;
    console.log(`Uploaded file ${file.displayName} as: ${file.name}`);
    return file;
  }
  
  /**
   * Waits for the given files to be active.
   *
   * Some files uploaded to the Gemini API need to be processed before they can
   * be used as prompt inputs. The status can be seen by querying the file's
   * "state" field.
   *
   * This implementation uses a simple blocking polling loop. Production code
   * should probably employ a more sophisticated approach.
   */
  async function waitForFilesActive(files) {
    console.log("Waiting for file processing...");
    for (const name of files.map((file) => file.name)) {
      let file = await fileManager.getFile(name);
      while (file.state === "PROCESSING") {
        process.stdout.write(".")
        await new Promise((resolve) => setTimeout(resolve, 10_000));
        file = await fileManager.getFile(name)
      }
      if (file.state !== "ACTIVE") {
        throw Error(`File ${file.name} failed to process`);
      }
    }
    console.log("...all files ready\n");
  }
  
  const model = genAI.getGenerativeModel({
    model: "gemini-2.0-flash-exp",
    systemInstruction: "I'm gonna give you docs. Please analyze them and create flashcards with the most important info that you find in the document. Please give the information in two arrays: one for the questions and one for the answers. Please only the arrays, no other text."
  });
  
  const generationConfig = {
    temperature: 1,
    topP: 0.95,
    topK: 40,
    maxOutputTokens: 8192,
    responseMimeType: "text/plain",
  };

  app.get("/create-flashcards", async (req, res) => {
    try {
      const url = req.query.url;
      if (!url) {
        return res.status(400).send("URL parameter is required");
      }
  
      // Log the URL being fetched for debugging
      console.log(`Fetching content from URL: ${url}`);
  
      const response = await fetch(url);
      const text = await response.text();
  
      // Log the fetched content length for debugging
      console.log(`Fetched content length: ${text.length}`);
  
      const chatSession = model.startChat({
        generationConfig,
        history: []
      });
  
      const result = await chatSession.sendMessage(text);
  
      // Log the AI result for debugging
      console.log(`AI response: ${result.response.text()}`);
  
      const flashcards = result.response.text();
  
      res.status(200).send({ flashcards });
    } catch (error) {
      console.error("Error creating flashcards:", error);
      res.status(500).send("An error occurred while creating flashcards");
    }
  });
  
  
  app.listen(PORT, () => {
    console.log(`Server is running on port ${PORT}`);
  });
    
  
  async function run() {
    // TODO Make these files available on the local file system
    // You may need to update the file paths
    const files = [
      
    ];
  
    // Some files have a processing delay. Wait for them to be ready.
    await waitForFilesActive(files);
  
    const chatSession = model.startChat({
      generationConfig,
      history: [
        {

        }
      ],
    });
  
    const result = await chatSession.sendMessage("INSERT_INPUT_HERE");
    console.log(result.response.text());
  }

//Peticion POST
